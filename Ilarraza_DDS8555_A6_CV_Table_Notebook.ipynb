{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "122a4717",
   "metadata": {},
   "source": [
    "# DDS8555 A6 — CV Table & Calibration Helper\n",
    "\n",
    "**Purpose.** Generate the exact numbers for the one‑pager results table (CV Accuracy ± SD, Macro‑F1 ± SD, PR‑AUC macro, OOB for Bagging, and Brier before→after for calibration).\n",
    "\n",
    "You can use **Option A** to recompute from your prepared `X, y`, or **Option B** to load precomputed CV means/SDs from `model_cv_summary.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e87220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np, pandas as pd, os, json\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, f1_score, average_precision_score, brier_score_loss\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# 5-fold CV with fixed seed\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "def cv_acc_f1(model, X, y):\n",
    "    acc = cross_val_score(model, X, y, cv=cv, scoring=\"accuracy\")\n",
    "    f1  = cross_val_score(model, X, y, cv=cv, scoring=\"f1_macro\")\n",
    "    return acc.mean(), acc.std(), f1.mean(), f1.std()\n",
    "\n",
    "def cv_prauc_macro(model, X, y):\n",
    "    prob = cross_val_predict(model, X, y, cv=cv, method=\"predict_proba\")\n",
    "    classes = np.unique(y)\n",
    "    Y = label_binarize(y, classes=classes)\n",
    "    return average_precision_score(Y, prob, average=\"macro\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cd8366",
   "metadata": {},
   "source": [
    "## Option A — Recompute from your prepared `X, y`\n",
    "Make sure `X` and `y` are defined in memory (same preprocessing as you used for Kaggle). Then run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df166ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models (match your Kaggle settings)\n",
    "dt = DecisionTreeClassifier(criterion=\"gini\", min_samples_leaf=3, random_state=123)\n",
    "bg = BaggingClassifier(estimator=DecisionTreeClassifier(min_samples_leaf=3, random_state=123),\n",
    "                       n_estimators=60, bootstrap=True, oob_score=True, random_state=123)\n",
    "rf = RandomForestClassifier(n_estimators=120, max_features=\"sqrt\", min_samples_leaf=2,\n",
    "                            random_state=123, n_jobs=-1)\n",
    "gb = GradientBoostingClassifier(n_estimators=80, learning_rate=0.05, max_depth=2, random_state=123)\n",
    "\n",
    "models = {'Decision Tree (leaf=3)': dt, 'Bagging (60 trees)': bg,\n",
    "          'Random Forest (120, sqrt)': rf, 'Gradient Boosting (depth=2, lr=0.05)': gb}\n",
    "\n",
    "results = {}\n",
    "try:\n",
    "    _ = X, y  # check existence\n",
    "    for name, mdl in models.items():\n",
    "        acc_m, acc_sd, f1_m, f1_sd = cv_acc_f1(mdl, X, y)\n",
    "        pr_auc = cv_prauc_macro(mdl, X, y)\n",
    "        results[name] = {'cv_acc_mean':acc_m, 'cv_acc_sd':acc_sd,\n",
    "                         'cv_f1_mean':f1_m, 'cv_f1_sd':f1_sd, 'pr_auc':pr_auc}\n",
    "    # OOB for Bagging\n",
    "    bg.fit(X, y)\n",
    "    results['Bagging (60 trees)']['oob'] = float(bg.oob_score_)\n",
    "    # Brier before/after for RF\n",
    "    rf.fit(X, y)\n",
    "    proba_raw = rf.predict_proba(X)\n",
    "    brier_before = brier_score_loss(label_binarize(y, classes=np.unique(y)).ravel(), proba_raw.ravel())\n",
    "    cal = CalibratedClassifierCV(rf, method='isotonic', cv=5)\n",
    "    cal.fit(X, y)\n",
    "    proba_cal = cal.predict_proba(X)\n",
    "    brier_after = brier_score_loss(label_binarize(y, classes=np.unique(y)).ravel(), proba_cal.ravel())\n",
    "    results['__brier__'] = {'before':float(brier_before), 'after':float(brier_after)}\n",
    "    print('Option A succeeded.')\n",
    "except NameError:\n",
    "    print('Option A skipped — X and y not found. Use Option B or define X,y and re-run.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6777e85",
   "metadata": {},
   "source": [
    "## Option B — Load from `/mnt/data/model_cv_summary.csv`\n",
    "If you exported CV means/SDs earlier, place them in this CSV with columns:\n",
    "`model, accuracy_mean, accuracy_sd, macro_f1_mean, macro_f1_sd`.\n",
    "This cell will also merge the Kaggle private/public scores and leave PR‑AUC/OOB blank unless you later run Option A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e8fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, os, json, math\n",
    "\n",
    "csv_path = '/mnt/data/model_cv_summary.csv'\n",
    "if os.path.exists(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # map names to the display names used in the table\n",
    "    alias = {'Model1_DecisionTree':'Decision Tree (leaf=3)',\n",
    "             'Model2_Bagging':'Bagging (60 trees)',\n",
    "             'Model3_RandomForest':'Random Forest (120, sqrt)',\n",
    "             'Model4_Boosting':'Gradient Boosting (depth=2, lr=0.05)'}\n",
    "    df['display'] = df['model'].map(alias).fillna(df['model'])\n",
    "    for _, r in df.iterrows():\n",
    "        name = r['display']\n",
    "        results.setdefault(name, {})\n",
    "        results[name].update({'cv_acc_mean':float(r['accuracy_mean']),\n",
    "                              'cv_acc_sd':float(r['accuracy_sd']),\n",
    "                              'cv_f1_mean':float(r['macro_f1_mean']),\n",
    "                              'cv_f1_sd':float(r['macro_f1_sd'])})\n",
    "    print('Loaded CV summary from CSV.')\n",
    "else:\n",
    "    print('CSV not found at', csv_path)\n",
    "\n",
    "# Kaggle scores (fill from your screenshot)\n",
    "kaggle = {\n",
    "    'Decision Tree (leaf=3)':  {'private':0.85585, 'public':0.86669},\n",
    "    'Bagging (60 trees)':      {'private':0.89333, 'public':0.89306},\n",
    "    'Random Forest (120, sqrt)': {'private':0.89721, 'public':0.89270},\n",
    "    'Gradient Boosting (depth=2, lr=0.05)': {'private':0.86750, 'public':0.86452},\n",
    "}\n",
    "for k,v in kaggle.items():\n",
    "    results.setdefault(k, {}).update({'k_private':v['private'], 'k_public':v['public']})\n",
    "\n",
    "# Persist intermediate results\n",
    "out_json = '/mnt/data/results_values.json'\n",
    "with open(out_json, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print('Saved intermediate metrics →', out_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e908d0a8",
   "metadata": {},
   "source": [
    "## Build the one‑pager table text\n",
    "This will round to **3 decimals** and write a Markdown table you can paste into Word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e8aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, numpy as np, os\n",
    "\n",
    "order = ['Decision Tree (leaf=3)', 'Bagging (60 trees)',\n",
    "         'Random Forest (120, sqrt)', 'Gradient Boosting (depth=2, lr=0.05)']\n",
    "\n",
    "def fmt(x):\n",
    "    return '—' if x is None or (isinstance(x,float) and (np.isnan(x))) else f\"{x:.3f}\"\n",
    "\n",
    "with open('/mnt/data/results_values.json') as f:\n",
    "    R = json.load(f)\n",
    "\n",
    "lines = []\n",
    "lines.append('| Model | CV Accuracy (±SD) | Macro-F1 (±SD) | PR-AUC (macro) | OOB Accuracy | Kaggle Private | Kaggle Public |')\n",
    "lines.append('| --- | --- | --- | --- | --- | --- | --- |')\n",
    "\n",
    "for name in order:\n",
    "    r = R.get(name, {})\n",
    "    acc = fmt(r.get('cv_acc_mean')) + ' ± ' + fmt(r.get('cv_acc_sd'))\n",
    "    f1  = fmt(r.get('cv_f1_mean'))  + ' ± ' + fmt(r.get('cv_f1_sd'))\n",
    "    pr  = fmt(r.get('pr_auc')) if r.get('pr_auc') is not None else '—'\n",
    "    oob = fmt(r.get('oob')) if r.get('oob') is not None else '—'\n",
    "    kp  = fmt(r.get('k_private'))\n",
    "    ku  = fmt(r.get('k_public'))\n",
    "    lines.append(f\"| {name} | {acc} | {f1} | {pr} | {oob} | {kp} | {ku} |\" )\n",
    "\n",
    "table_md = '\\n'.join(lines)\n",
    "md_path = '/mnt/data/onepager_table_filled.md'\n",
    "with open(md_path, 'w') as f:\n",
    "    f.write(table_md)\n",
    "\n",
    "# Brier before→after line (if available)\n",
    "brier = R.get('__brier__', {})\n",
    "brier_text = (f\"Brier (before → after): {fmt(brier.get('before'))} → {fmt(brier.get('after'))}\"\n",
    "              if brier else 'Brier (before → after): — → —')\n",
    "brier_path = '/mnt/data/brier_line.txt'\n",
    "with open(brier_path, 'w') as f:\n",
    "    f.write(brier_text)\n",
    "\n",
    "print('Wrote:')\n",
    "print(' -', md_path)\n",
    "print(' -', brier_path)\n",
    "print('\\nPreview:')\n",
    "print(table_md)\n",
    "print('\\n' + brier_text)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
